{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9af1d2cd",
      "metadata": {
        "id": "9af1d2cd"
      },
      "source": [
        "## Data preparation pipeline \n",
        "This notebook holds all the process of datapreperation to the traning and validation:\n",
        "It posses the following tasks:\n",
        "- Fetching raw text data from a dataset\n",
        "- annotating the data with POS and NER annotations\n",
        "- save the annotated data in batch to an online bucket\n",
        "This pipeline has foult tolerace mechanisem that in case of failer, save the progress in come back to it when rerun. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a73c7f",
      "metadata": {},
      "source": [
        "### Google authentication\n",
        "This pipeline was executed from google Colab, so the authentication and the disk I/O was used via google and google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "_Wdj0Q6DvHGA",
      "metadata": {
        "id": "_Wdj0Q6DvHGA"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h5cTC9EQvYgc",
      "metadata": {
        "id": "h5cTC9EQvYgc"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "from google.colab import drive\n",
        "\n",
        "gcs_service = build('storage', 'v1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f88715b",
      "metadata": {},
      "source": [
        "A save Driver is an entity that resposible to save the annotated items to a bucket in a batch, and save the progress of the running pipline.\n",
        "We created an abstract Driver and implemented for local (for testing, see other files) and cloud usage - as parqute and none-parqute files (for actual executing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E_he16XxpWQO",
      "metadata": {
        "id": "E_he16XxpWQO"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "class BaseSaveDriver(ABC):\n",
        "    \"\"\"\n",
        "    Abstract base class for save drivers.\n",
        "    Allows different storage implementations (local, cloud, etc.).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batch_size: int = 100):\n",
        "        \"\"\"\n",
        "        Initialize the base save driver.\n",
        "\n",
        "        Args:\n",
        "            batch_size: Number of documents per batch\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.current_batch = []\n",
        "        self.batch_count = 0\n",
        "        self.documents_processed = 0\n",
        "\n",
        "    @abstractmethod\n",
        "    def add_document(self, document):\n",
        "        \"\"\"Add a document to the current batch.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def finalize(self):\n",
        "        \"\"\"Save any remaining documents and return statistics.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_statistics(self):\n",
        "        \"\"\"Get current statistics.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def _save_current_batch(self):\n",
        "        \"\"\"Abstract method to save the current batch to storage.\"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2d0e7c",
      "metadata": {},
      "source": [
        "## Annotating the data\n",
        "SpacyJSONGenerator is the entity that given a driver and a dataset orchestrate the operation of annotating the data and saving ordering the driver to save it in batches. \n",
        "The annotation job is done using en_core_web_trf model from Spacy - an open source NLP proccecing platfrom which expose different NLP models for verity of usage.\n",
        "The procces is done via process_and_save method in SpacyJSONGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72c63d3",
      "metadata": {
        "id": "c72c63d3"
      },
      "outputs": [],
      "source": [
        "from spacy.pipeline import EntityRuler\n",
        "import spacy\n",
        "import re\n",
        "from typing import List, Dict, Any, Iterator\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import tempfile\n",
        "import uuid\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "\n",
        "class SpacyJSONGenerator:\n",
        "    def __init__(self, batch_size: int = 100, n_process: int = 1, require_gpu: bool = False):\n",
        "        \"\"\"\n",
        "        Initialize the generator with batching capabilities.\n",
        "\n",
        "        Args:\n",
        "            batch_size: Number of texts (sentences) to process in each batch\n",
        "            n_process: Number of processes for parallel processing (use -1 for all cores)\n",
        "        \"\"\"\n",
        "        # Load the transformer model\n",
        "        if require_gpu:\n",
        "            spacy.require_gpu()\n",
        "        self.nlp = spacy.load(\"en_core_web_trf\", disable=[\"lemmatizer\"])\n",
        "        self.batch_size = batch_size\n",
        "        self.n_process = n_process\n",
        "\n",
        "        # Add EntityRuler for NLE extraction (BEFORE NER for better integration)\n",
        "        ruler = self.nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "        self._setup_nle_patterns(ruler)\n",
        "\n",
        "    def _setup_nle_patterns(self, ruler: EntityRuler):\n",
        "        \"\"\"Setup patterns for Nonlinguistic Entity extraction using EntityRuler.\"\"\"\n",
        "        patterns = [\n",
        "            # Phone patterns\n",
        "            {\"label\": \"PHONE\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}\"}}]},\n",
        "            {\"label\": \"PHONE\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"\\+[1-9]\\d{1,14}\"}}]},\n",
        "\n",
        "            # Address patterns\n",
        "            {\"label\": \"ADDRESS\", \"pattern\": [{\"IS_DIGIT\": True}, {\"IS_ALPHA\": True, \"OP\": \"+\"}, {\"LOWER\": {\"IN\": [\"st\", \"street\", \"ave\", \"avenue\", \"rd\", \"road\", \"blvd\", \"boulevard\", \"dr\", \"drive\", \"ln\", \"lane\", \"ct\", \"court\", \"pl\", \"place\"]}}]},\n",
        "            {\"label\": \"ADDRESS\", \"pattern\": [{\"LOWER\": \"p\"}, {\"TEXT\": \".\"}, {\"LOWER\": \"o\"}, {\"TEXT\": \".\"}, {\"LOWER\": \"box\"}, {\"IS_DIGIT\": True}]},\n",
        "\n",
        "            # IP Address patterns\n",
        "            {\"label\": \"IP_ADDRESS\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b\"}}]},\n",
        "            {\"label\": \"IP_ADDRESS\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"\\b(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}\\b\"}}]},\n",
        "\n",
        "            # SSN patterns\n",
        "            {\"label\": \"SSN\", \"pattern\": [{\"IS_DIGIT\": True, \"LENGTH\": 3}, {\"TEXT\": \"-\"}, {\"IS_DIGIT\": True, \"LENGTH\": 2}, {\"TEXT\": \"-\"}, {\"IS_DIGIT\": True, \"LENGTH\": 4}]},\n",
        "            {\"label\": \"SSN\", \"pattern\": [{\"IS_DIGIT\": True, \"LENGTH\": 3}, {\"IS_SPACE\": True}, {\"IS_DIGIT\": True, \"LENGTH\": 2}, {\"IS_SPACE\": True}, {\"IS_DIGIT\": True, \"LENGTH\": 4}]},\n",
        "\n",
        "            # URL and Email patterns (using built-ins)\n",
        "            {\"label\": \"URL\", \"pattern\": [{\"LIKE_URL\": True}]},\n",
        "            {\"label\": \"EMAIL\", \"pattern\": [{\"LIKE_EMAIL\": True}]}\n",
        "        ]\n",
        "\n",
        "        ruler.add_patterns(patterns)\n",
        "\n",
        "\n",
        "    def _extract_punctuation_spans(self, text: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extract punctuation spans from text.\"\"\"\n",
        "        punct_spans = []\n",
        "        punct_pattern = r'[^\\w\\s]'  # Match non-word, non-space characters\n",
        "\n",
        "        for match in re.finditer(punct_pattern, text):\n",
        "            punct_spans.append({\n",
        "                \"start\": match.start(),\n",
        "                \"end\": match.end(),\n",
        "                \"value\": match.group()\n",
        "            })\n",
        "\n",
        "        return punct_spans\n",
        "\n",
        "    def _extract_special_tags_from_doc(self, doc) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Extract special tags from spaCy doc (NLEs are now in doc.ents).\"\"\"\n",
        "        special_tags = []\n",
        "\n",
        "        # Filter NLE entities (non-standard NER labels)\n",
        "        nle_labels = {\"PHONE\", \"ADDRESS\", \"IP_ADDRESS\", \"SSN\", \"URL\", \"EMAIL\"}\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in nle_labels:\n",
        "                special_tags.append({\n",
        "                    \"start\": ent.start_char,\n",
        "                    \"end\": ent.end_char,\n",
        "                    \"type\": ent.label_,\n",
        "                    \"value\": ent.text\n",
        "                })\n",
        "\n",
        "        return special_tags\n",
        "\n",
        "    def _get_sentence_spans(self, doc, text: str) -> List[Dict[str, int]]:\n",
        "        \"\"\"Extract sentence spans.\"\"\"\n",
        "        sent_spans = []\n",
        "        for sent in doc.sents:\n",
        "            sent_spans.append({\n",
        "                \"start\": sent.start_char,\n",
        "                \"end\": sent.end_char\n",
        "            })\n",
        "        return sent_spans\n",
        "\n",
        "    def process_single_doc(self, doc, original_text: str, sentence_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"Process a single spaCy doc and return the JSON structure.\"\"\"\n",
        "\n",
        "        # Extract sentence spans\n",
        "        sent_spans = self._get_sentence_spans(doc, original_text)\n",
        "\n",
        "        # Extract punctuation spans\n",
        "        punct_spans = self._extract_punctuation_spans(original_text)\n",
        "\n",
        "        # Extract special tags (NLEs) from doc.ents\n",
        "        special_tags = self._extract_special_tags_from_doc(doc)\n",
        "\n",
        "        # Extract named entity spans with entity IDs (standard NER only)\n",
        "        ner_spans = []\n",
        "        nle_labels = {\"PHONE\", \"ADDRESS\", \"IP_ADDRESS\", \"SSN\", \"URL\", \"EMAIL\"}\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            # Only include standard NER entities, not NLEs\n",
        "            if ent.label_ not in nle_labels:\n",
        "                ner_spans.append({\n",
        "                    \"entity_id\": f\"{ent.label_}-{str(ent).upper().replace(' ', '_').replace('-', '_')}\",\n",
        "                    \"start\": ent.start_char,\n",
        "                    \"end\": ent.end_char,\n",
        "                    \"label\": ent.label_\n",
        "                })\n",
        "\n",
        "        # Extract POS tokens and tags\n",
        "        pos_tokens = []\n",
        "        pos_tags = []\n",
        "        ner_iob = []\n",
        "\n",
        "        for token in doc:\n",
        "            # Skip whitespace-only tokens\n",
        "            if not token.text.strip():\n",
        "                continue\n",
        "\n",
        "            pos_tokens.append(token.text)\n",
        "            pos_tags.append(token.pos_)\n",
        "\n",
        "            # Determine IOB tag\n",
        "            if token.ent_iob_ == 'B':\n",
        "                ner_iob.append(f\"B-{token.ent_type_}\")\n",
        "            elif token.ent_iob_ == 'I':\n",
        "                ner_iob.append(f\"I-{token.ent_type_}\")\n",
        "            else:\n",
        "                ner_iob.append(\"O\")\n",
        "\n",
        "        # Build the final JSON structure\n",
        "        result = {\n",
        "            \"id\": sentence_id,\n",
        "            \"text\": original_text,\n",
        "            \"sent_spans\": sent_spans,\n",
        "            \"punct_spans\": punct_spans,\n",
        "            \"special_tags\": special_tags,\n",
        "            \"ner_spans\": ner_spans,\n",
        "            \"pos_tokens\": pos_tokens,\n",
        "            \"pos_tags\": pos_tags,\n",
        "            \"ner_iob\": ner_iob\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def process_sentences_batch(self, sentences: List[str], sentence_ids: List[str] = None):\n",
        "        \"\"\"Process a batch of sentences efficiently.\"\"\"\n",
        "        if sentence_ids is None:\n",
        "            sentence_ids = [f\"sent_{str(uuid.uuid4())}\" for _ in range(len(sentences))]\n",
        "\n",
        "        # Process batch with spaCy\n",
        "        docs = list(self.nlp.pipe(sentences, batch_size=self.batch_size, n_process=self.n_process))\n",
        "\n",
        "        # Process each doc\n",
        "        results = []\n",
        "        for doc, original_text, sent_id in zip(docs, sentences, sentence_ids):\n",
        "            result = self.process_single_doc(doc, original_text, sent_id)\n",
        "            results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    def _clear_gpu_memory(self):\n",
        "            if torch.cuda.is_available():\n",
        "              print(\"free up memory\")\n",
        "              torch.cuda.empty_cache()\n",
        "              gc.collect()\n",
        "\n",
        "    def process_and_save(self, dataset, save_driver: BaseSaveDriver, num_batches=None, resume_from_progress=True):\n",
        "        \"\"\"\n",
        "        Process dataset using Hugging Face map() function with configurable save driver.\n",
        "        Includes detailed timing measurements and bottleneck analysis.\n",
        "\n",
        "        Args:\n",
        "            dataset: Hugging Face dataset\n",
        "            save_driver: SaveDriver instance for handling storage (local, cloud, etc.)\n",
        "            num_batches: Number of batches to process (None = process all)\n",
        "            resume_from_progress: Whether to resume from existing progress (if available)\n",
        "\n",
        "        Returns:\n",
        "            BaseSaveDriver: The save driver instance with statistics\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"🚀 Starting HF map() optimized processing with {save_driver.__class__.__name__}...\")\n",
        "\n",
        "        # Check if we should resume from existing progress\n",
        "        documents_to_skip = 0\n",
        "        initial_batch_count = 0\n",
        "        if resume_from_progress and hasattr(save_driver, 'progress_data'):\n",
        "            progress = save_driver.progress_data\n",
        "            if progress['documents_processed'] > 0:\n",
        "                documents_to_skip = progress['documents_processed']\n",
        "                initial_batch_count = progress['batch_count']\n",
        "\n",
        "                print(f\"🔄 Resuming from previous progress:\")\n",
        "                print(f\"   📄 Documents already processed: {progress['documents_processed']}\")\n",
        "                print(f\"   📦 Batches already created: {progress['batch_count']}\")\n",
        "                print(f\"⏭️  Skipping first {documents_to_skip} documents...\")\n",
        "\n",
        "\n",
        "\n",
        "        def process_batch_texts(batch):\n",
        "            \"\"\"Process a batch of texts with spaCy using HF map.\"\"\"\n",
        "\n",
        "            texts = [text for text in batch['text'] if len(text) >= 10]\n",
        "\n",
        "            if not texts:\n",
        "                return {'processed': [None] * len(batch['text'])}\n",
        "\n",
        "            try:\n",
        "                processed_docs = self.process_sentences_batch(texts)\n",
        "                return {'processed': processed_docs}\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error processing batch: {e}\")\n",
        "                return {'processed': [None] * len(batch['text'])}\n",
        "\n",
        "        print(f\"Skipping documents (if needed) and adding mapping\")\n",
        "        processed_dataset = dataset['train'].skip(documents_to_skip ).map(\n",
        "            process_batch_texts,\n",
        "            batched=True,\n",
        "            batch_size=self.batch_size,\n",
        "            remove_columns=['text']\n",
        "        )\n",
        "\n",
        "        print(\"💾 Processing and saving data...\")\n",
        "\n",
        "        processed_count = 0\n",
        "\n",
        "        try:\n",
        "            for example in processed_dataset:\n",
        "\n",
        "\n",
        "                save_driver.add_document(example['processed'])\n",
        "                processed_count += 1\n",
        "\n",
        "                # Check batch count more frequently to respect num_batches limit\n",
        "                current_batch_count = save_driver.batch_count\n",
        "                new_batches_created = current_batch_count - initial_batch_count\n",
        "\n",
        "                if processed_count % save_driver.batch_size == 0:\n",
        "                  self._clear_gpu_memory()\n",
        "\n",
        "                # Check if we've processed enough NEW batches (check after each document)\n",
        "                if num_batches is not None and new_batches_created >= num_batches:\n",
        "                    print(f\"🛑 Reached target of {num_batches} new batches. Stopping...\")\n",
        "                    print(f\"   📊 Total batches: {current_batch_count}, New batches this run: {new_batches_created}\")\n",
        "                    break\n",
        "\n",
        "\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n⚠️  Processing interrupted by user. Progress saved.\")\n",
        "            if hasattr(save_driver, '_save_progress'):\n",
        "                save_driver._save_progress()\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Processing failed: {e}\")\n",
        "            print(\"💾 Progress saved. You can resume later.\")\n",
        "            if hasattr(save_driver, '_save_progress'):\n",
        "                save_driver._save_progress()\n",
        "            raise\n",
        "\n",
        "\n",
        "        # Finalize and get statistics\n",
        "        batch_count, documents_processed = save_driver.finalize()\n",
        "\n",
        "        # Calculate total time and performance metrics\n",
        "\n",
        "        print(f\"\\n🎉 Processing completed!\")\n",
        "        print(f\"📊 Performance Summary:\")\n",
        "        print(f\"   📄 Documents processed: {documents_processed}\")\n",
        "        print(f\"   📦 Batches created: {batch_count}\")\n",
        "\n",
        "        return save_driver\n",
        "\n",
        "class CloudSaveDriver(BaseSaveDriver):\n",
        "    \"\"\"\n",
        "    Google Cloud Storage (GCS) implementation for saving processed batches.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bucket_name=None, project_id=None, batch_size=100, progress_file=\"gcs_processing_progress.json\"):\n",
        "        \"\"\"\n",
        "        Initialize the CloudSaveDriver with GCS support.\n",
        "\n",
        "        Args:\n",
        "            bucket_name: GCS bucket name (optional, can be set in config)\n",
        "            batch_size: Number of documents per batch file\n",
        "            progress_file: File to store processing progress for resumption\n",
        "        \"\"\"\n",
        "        super().__init__(batch_size)\n",
        "        self.progress_path = '/content/drive/MyDrive/nlp-3523-final-project/' + progress_file\n",
        "        self.colab_drive = drive\n",
        "        self._mount_drive()\n",
        "        self.progress_data = self._load_progress()\n",
        "        self.GCS_RETRY_ATTEMPTS = 5\n",
        "\n",
        "        # Import here to avoid dependency issues if GCS not installed\n",
        "        try:\n",
        "            from google.cloud import storage\n",
        "            from google.cloud.exceptions import GoogleCloudError\n",
        "        except ImportError as e:\n",
        "            raise ImportError(f\"GCS dependencies not installed. Run: pip install google-cloud-storage. Error: {e}\")\n",
        "        # Store imports for use in methods\n",
        "        self.storage = storage\n",
        "        self.GoogleCloudError = GoogleCloudError\n",
        "        # Validate and get GCS configuration\n",
        "        try:\n",
        "            self.bucket_name = bucket_name\n",
        "            self.project_id = project_id\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"GCS configuration error: {e}\")\n",
        "        # Initialize GCS client\n",
        "        try:\n",
        "            # Credentials from file path\n",
        "\n",
        "            self.client  = storage.Client()\n",
        "\n",
        "            # Get bucket reference\n",
        "            self.bucket = self.client.bucket(self.bucket_name)\n",
        "\n",
        "            # Test bucket access\n",
        "            if not self.bucket.exists():\n",
        "                raise ValueError(f\"Bucket '{self.bucket_name}' does not exist or is not accessible\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to initialize GCS client: {e}\")\n",
        "\n",
        "        print(f\"☁️  CloudSaveDriver (GCS) initialized:\")\n",
        "        print(f\"  - Bucket: {self.bucket_name}\")\n",
        "        print(f\"  - Project: {self.project_id}\")\n",
        "        print(f\"  - Batch size: {self.batch_size}\")\n",
        "\n",
        "        # Restore state from progress file\n",
        "        if self.progress_data['documents_processed'] > 0:\n",
        "            self.documents_processed = self.progress_data['documents_processed']\n",
        "            self.batch_count = self.progress_data['batch_count']\n",
        "            print(f\"  - Resuming from: {self.documents_processed} docs, {self.batch_count} batches\")\n",
        "\n",
        "    def _mount_drive(self):\n",
        "        \"\"\"Mount the drive.\"\"\"\n",
        "        if not os.path.exists('/content/drive/My Drive'):\n",
        "            print(\"🔗 Mounting Google Drive...\")\n",
        "            self.colab_drive.mount('/content/drive')\n",
        "            print(\"✅ Google Drive mounted successfully\")\n",
        "        else:\n",
        "            print(\"✅ Google Drive already mounted\")\n",
        "\n",
        "    def _load_progress(self):\n",
        "        \"\"\"Load existing progress if available.\"\"\"\n",
        "        if os.path.exists(self.progress_path):\n",
        "            try:\n",
        "                with open(self.progress_path, 'r') as f:\n",
        "                    progress = json.load(f)\n",
        "                    print(f\"📋 Loaded existing progress: {progress['documents_processed']} docs, {progress['batch_count']} batches\")\n",
        "                    return progress\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  Could not load progress file: {e}\")\n",
        "        else:\n",
        "        # create that file:\n",
        "            with open(self.progress_path, 'w') as f:\n",
        "                json.dump({'documents_processed': 0, 'batch_count': 0, 'start_time': time.time()}, f, indent=2)\n",
        "                print(\"created progress file\")\n",
        "\n",
        "\n",
        "        return {\n",
        "            'documents_processed': 0,\n",
        "            'batch_count': 0,\n",
        "            'start_time': time.time()\n",
        "        }\n",
        "\n",
        "    def _save_progress(self):\n",
        "        \"\"\"Save current progress to file.\"\"\"\n",
        "        print(\"save progress\")\n",
        "        self.progress_data.update({\n",
        "            'documents_processed': self.documents_processed,\n",
        "            'batch_count': self.batch_count,\n",
        "            'last_save_time': time.time()\n",
        "        })\n",
        "\n",
        "        try:\n",
        "            with open(self.progress_path, 'w') as f:\n",
        "                json.dump(self.progress_data, f, indent=2)\n",
        "                print(\"saved pregress\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Could not save progress: {e}\")\n",
        "\n",
        "    def add_document(self, document):\n",
        "        \"\"\"\n",
        "        Add a document to the current batch.\n",
        "\n",
        "        Args:\n",
        "            document: Processed document to add\n",
        "        \"\"\"\n",
        "        if document is not None:\n",
        "            self.current_batch.append(document)\n",
        "            self.documents_processed += 1\n",
        "\n",
        "            # Save batch when it reaches the desired size\n",
        "            if len(self.current_batch) >= self.batch_size:\n",
        "                self._save_current_batch()\n",
        "\n",
        "    def _save_current_batch(self):\n",
        "        \"\"\"\n",
        "        Save the current batch to GCS bucket.\n",
        "        \"\"\"\n",
        "        if not self.current_batch:\n",
        "            return\n",
        "\n",
        "        save_start = time.time()\n",
        "        self.batch_count += 1\n",
        "\n",
        "        # Create filename with timestamp and batch number\n",
        "        timestamp = int(time.time())\n",
        "        filename = f\"batch_{self.batch_count:06d}_{timestamp}.json\"\n",
        "\n",
        "        try:\n",
        "            print(\"save batch\")\n",
        "            # Create temporary file for JSON data\n",
        "            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:\n",
        "                json.dump(self.current_batch, temp_file, ensure_ascii=False)\n",
        "                temp_file_path = temp_file.name\n",
        "\n",
        "            blob = self.bucket.blob(filename)\n",
        "\n",
        "            for attempt in range(self.GCS_RETRY_ATTEMPTS):\n",
        "                try:\n",
        "                    blob.upload_from_filename(temp_file_path, content_type='application/json')\n",
        "\n",
        "                    break\n",
        "                except self.GoogleCloudError as e:\n",
        "                    if attempt == self.GCS_RETRY_ATTEMPTS - 1:\n",
        "                        raise\n",
        "                    print(f\"⚠️  Upload attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
        "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "                # Configure upload settings for large files\n",
        "                # blob.chunk_size = self.config.GCS_UPLOAD_CHUNK_SIZE # default is 100MB\n",
        "\n",
        "                # Upload with retry logic\n",
        "\n",
        "            os.unlink(temp_file_path)  # Clean up\n",
        "\n",
        "            save_time = time.time() - save_start\n",
        "            file_size_mb = len(json.dumps(self.current_batch)) / 1024 / 1024\n",
        "\n",
        "            print(f\"☁️  Saved batch {self.batch_count} with {len(self.current_batch)} documents to gs://{self.bucket_name}/{filename}\")\n",
        "            print(f\"   ⏱️  Upload time: {save_time:.3f}s, Size: {file_size_mb:.1f} MB, Rate: {len(self.current_batch)/save_time:.1f} docs/sec\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save batch {self.batch_count} to GCS: {e}\")\n",
        "            # Clean up temp file if it exists\n",
        "            try:\n",
        "                if 'temp_file_path' in locals():\n",
        "                    os.unlink(temp_file_path)\n",
        "            except:\n",
        "                pass\n",
        "            raise\n",
        "\n",
        "        # Save progress after each batch\n",
        "        self._save_progress()\n",
        "\n",
        "        # Clear current batch to free memory\n",
        "        self.current_batch = []\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"\n",
        "        Save any remaining documents and return statistics.\n",
        "        \"\"\"\n",
        "        finalize_start = time.time()\n",
        "\n",
        "        # Save remaining documents if any\n",
        "        if self.current_batch:\n",
        "            print(f\"🔄 Finalizing: saving remaining {len(self.current_batch)} documents to GCS...\")\n",
        "            self._save_current_batch()\n",
        "\n",
        "        finalize_time = time.time() - finalize_start\n",
        "        print(f\"✅ GCS finalization completed in {finalize_time:.3f}s\")\n",
        "        print(f\"📊 CloudSaveDriver (GCS) completed:\")\n",
        "        print(f\"  - Total batches: {self.batch_count}\")\n",
        "        print(f\"  - Total documents: {self.documents_processed}\")\n",
        "        print(f\"  - Bucket: gs://{self.bucket_name}\")\n",
        "\n",
        "        # Clean up progress file on successful completion\n",
        "        # if os.path.exists(self.progress_file):\n",
        "        #     os.remove(self.progress_file)\n",
        "        #     print(\"🧹 Cleaned up progress file\")\n",
        "\n",
        "        return self.batch_count, self.documents_processed\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"Get current statistics.\"\"\"\n",
        "        return {\n",
        "            'batches_created': self.batch_count,\n",
        "            'documents_processed': self.documents_processed,\n",
        "            'current_batch_size': len(self.current_batch),\n",
        "            'storage_type': 'gcs',\n",
        "            'bucket_name': self.bucket_name,\n",
        "            'project_id': self.project_id\n",
        "        }\n",
        "\n",
        "    def list_batches(self):\n",
        "        \"\"\"\n",
        "        List all batch files in the GCS bucket.\n",
        "\n",
        "        Returns:\n",
        "            list: List of blob objects representing batch files\n",
        "        \"\"\"\n",
        "        try:\n",
        "            blobs = list(self.bucket.list_blobs(prefix=\"batch_\"))\n",
        "            return sorted(blobs, key=lambda x: x.name)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to list batches from GCS: {e}\")\n",
        "            return []\n",
        "\n",
        "    def load_batch(self, blob):\n",
        "        \"\"\"\n",
        "        Load a batch from GCS.\n",
        "\n",
        "        Args:\n",
        "            blob: GCS blob object or blob name\n",
        "\n",
        "        Returns:\n",
        "            list: List of processed documents\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if isinstance(blob, str):\n",
        "                blob = self.bucket.blob(blob)\n",
        "\n",
        "            # Download to temporary file\n",
        "            with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as temp_file:\n",
        "                blob.download_to_filename(temp_file.name)\n",
        "\n",
        "                # Load JSON data\n",
        "                with open(temp_file.name, 'r', encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                # Clean up\n",
        "                import os\n",
        "                os.unlink(temp_file.name)\n",
        "\n",
        "                return data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load batch from GCS: {e}\")\n",
        "            return []\n",
        "class CloudParquetSaveDriver(CloudSaveDriver):\n",
        "    \"\"\"\n",
        "    Google Cloud Storage (GCS) implementation for saving processed batches to parquet files.\n",
        "    \"\"\"\n",
        "    def __init__(self, bucket_name=None, project_id=None, batch_size=100, progress_file=\"gcs_processing_progress.json\"):\n",
        "        super().__init__(bucket_name, project_id, batch_size, progress_file)\n",
        "\n",
        "    def _save_current_batch(self):\n",
        "        \"\"\"\n",
        "        Save the current batch to GCS bucket.\n",
        "        \"\"\"\n",
        "        if not self.current_batch:\n",
        "            return\n",
        "\n",
        "        self.batch_count += 1\n",
        "\n",
        "        # Create filename with timestamp and batch number\n",
        "        timestamp = int(time.time())\n",
        "        filename = f\"batch_{self.batch_count:06d}_{timestamp}.parquet\"\n",
        "        save_start = time.time()\n",
        "        try:\n",
        "            # Create temporary file for Parquet data\n",
        "            with tempfile.NamedTemporaryFile(mode='w', suffix='.parquet', delete=False) as temp_file:\n",
        "                pa.Table.from_pylist(self.current_batch).to_pandas().to_parquet(temp_file.name)\n",
        "                temp_file_path = temp_file.name\n",
        "\n",
        "                blob = self.bucket.blob(filename)\n",
        "\n",
        "                for attempt in range(self.GCS_RETRY_ATTEMPTS):\n",
        "                    try:\n",
        "                        blob.upload_from_filename(temp_file_path, content_type='application/parquet')\n",
        "\n",
        "                        break\n",
        "                    except self.GoogleCloudError as e:\n",
        "                        if attempt == self.GCS_RETRY_ATTEMPTS - 1:\n",
        "                            raise\n",
        "                        print(f\"⚠️  Upload attempt {attempt + 1} failed, retrying... Error: {e}\")\n",
        "                        time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "                os.unlink(temp_file_path)  # Clean up\n",
        "\n",
        "                save_time = time.time() - save_start\n",
        "                file_size_mb = len(json.dumps(self.current_batch)) / 1024 / 1024\n",
        "\n",
        "                print(f\"☁️  Saved batch {self.batch_count} with {len(self.current_batch)} documents to gs://{self.bucket_name}/{filename}\")\n",
        "                print(f\"   ⏱️  Upload time: {save_time:.3f}s, Size: {file_size_mb:.1f} MB, Rate: {len(self.current_batch)/save_time:.1f} docs/sec\")\n",
        "\n",
        "                self._save_progress()\n",
        "                del self.current_batch\n",
        "                gc.collect()\n",
        "                self.current_batch = []\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save batch {self.batch_count} to GCS: {e}\")\n",
        "            # Clean up temp file if it exists\n",
        "            try:\n",
        "                if 'temp_file_path' in locals():\n",
        "                    os.unlink(temp_file_path)\n",
        "            except:\n",
        "                pass\n",
        "            raise\n",
        "\n",
        "\n",
        "    def load_batch(self, blob):\n",
        "        \"\"\"\n",
        "        Load a batch from GCS.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if isinstance(blob, str):\n",
        "                blob = self.bucket.blob(blob)\n",
        "            else:\n",
        "                # Download to temporary file\n",
        "                with tempfile.NamedTemporaryFile(mode='w+', suffix='.parquet', delete=False) as temp_file:\n",
        "                    blob.download_to_filename(temp_file.name)\n",
        "\n",
        "                    # Load Parquet data\n",
        "                    table = pq.read_table(temp_file.name)\n",
        "\n",
        "                    # Clean up\n",
        "                    os.unlink(temp_file.name)\n",
        "\n",
        "                    return table.to_pylist()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load batch from GCS: {e}\")\n",
        "            return []\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4415eeae",
      "metadata": {},
      "source": [
        "Downloadding the Space model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Ojy7lkFrrXDd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojy7lkFrrXDd",
        "outputId": "696c6bb5-a81e-43f0-e278-12f3bc2cc08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-trf==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "Requirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from en-core-web-trf==3.8.0) (0.3.1)\n",
            "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.1.1)\n",
            "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.0.9)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.12/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_trf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3xuFwv0utVM4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xuFwv0utVM4",
        "outputId": "d9e4bdba-2c28-4b80-9e83-5fbecd43defb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets==3.6.0 in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==3.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "LcCHxYzFq6eF",
      "metadata": {
        "id": "LcCHxYzFq6eF"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "af15f6fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "3af4108409164ad0a5fffae05b809f48",
            "e839b9ea4de54ae5b44f819188f12ad7",
            "ea03e9ddf22e4dcca85d530160a3742a",
            "744df0015d3543679897f4310728b123",
            "08f92146def348cbb0e69d82af358544",
            "061c2cf4e2ec41e6a558086c21ef7d09",
            "62445e6e258e451b9f229794b07976df",
            "1d200755d6fa48f6b6491235e01eb1b0",
            "83fc42b134f049ca98ef711cb8c6fcbf",
            "1347ab833edf461ab333efd247e65f1a",
            "3fe1e722806b419898e966f4e99dd2c8",
            "05cff43e9b084c638ac6233a7974812e",
            "7024a207045e4a53ab651bd169ddd842",
            "c2d4763783b442baa2254ba1fcc1f95c",
            "4cb74bbc86d841c1a21f301441dcec06",
            "3e1bfcebf9a64a0fb6859b1f7265ed07",
            "7ff5e164c162440e82c15a7c5dea8188",
            "e33fd3cde50a4f579c2314282e3d76d7",
            "b8cc479375f7498a810287622998c015",
            "28fa45df03fe427fb37cbd0c62b9b434",
            "4882b9e945904c8f8e2c86d1cf3b4324",
            "946a340620484b5dbf5052a77da93923"
          ]
        },
        "id": "af15f6fe",
        "outputId": "406c4549-ee72-45d5-a488-1a041b991ab7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3af4108409164ad0a5fffae05b809f48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05cff43e9b084c638ac6233a7974812e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "openwebtext.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generator = SpacyJSONGenerator(batch_size=100, n_process=1,require_gpu=True)\n",
        "dataset = load_dataset(\"Skylion007/openwebtext\", trust_remote_code=True, streaming=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a9652b",
      "metadata": {},
      "source": [
        "Creating the Driver with our bucket address"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9df0457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9df0457",
        "outputId": "4cf634e6-cc09-4c82-89d6-4a66e88ee65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔗 Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted successfully\n",
            "📋 Loaded existing progress: 112500 docs, 225 batches\n",
            "☁️  CloudSaveDriver (GCS) initialized:\n",
            "  - Bucket: parquet_v2_openwebtext-with-pos-ner\n",
            "  - Project: eastern-bridge-472408-d3\n",
            "  - Batch size: 500\n",
            "  - Resuming from: 112500 docs, 225 batches\n"
          ]
        }
      ],
      "source": [
        "gcs_save_driver = CloudParquetSaveDriver(\n",
        "    bucket_name=\"parquet_v2_openwebtext-with-pos-ner\",\n",
        "    project_id=\"eastern-bridge-472408-d3\",\n",
        "    batch_size=500  \n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DiTmidF2tAA0",
      "metadata": {
        "id": "DiTmidF2tAA0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "60a95d22",
      "metadata": {},
      "source": [
        "Executing the process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "766de082",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "766de082",
        "outputId": "0baa71b6-b143-4c37-d790-9bec0fa88f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting HF map() optimized processing with CloudParquetSaveDriver...\n",
            "🔄 Resuming from previous progress:\n",
            "   📄 Documents already processed: 112500\n",
            "   📦 Batches already created: 225\n",
            "⏭️  Skipping first 112500 documents...\n",
            "Skipping documents (if needed) and adding mapping\n",
            "💾 Processing and saving data...\n",
            "✅ GCS finalization completed in 0.000s\n",
            "📊 CloudSaveDriver (GCS) completed:\n",
            "  - Total batches: 225\n",
            "  - Total documents: 112500\n",
            "  - Bucket: gs://parquet_v2_openwebtext-with-pos-ner\n",
            "\n",
            "🎉 Processing completed!\n",
            "📊 Performance Summary:\n",
            "   📄 Documents processed: 112500\n",
            "   📦 Batches created: 225\n"
          ]
        }
      ],
      "source": [
        "result_driver = generator.process_and_save(\n",
        "            dataset=dataset,\n",
        "            save_driver=gcs_save_driver\n",
        "            # num_batches=2  # Process the whole dataset\n",
        "        )\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05cff43e9b084c638ac6233a7974812e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7024a207045e4a53ab651bd169ddd842",
              "IPY_MODEL_c2d4763783b442baa2254ba1fcc1f95c",
              "IPY_MODEL_4cb74bbc86d841c1a21f301441dcec06"
            ],
            "layout": "IPY_MODEL_3e1bfcebf9a64a0fb6859b1f7265ed07"
          }
        },
        "061c2cf4e2ec41e6a558086c21ef7d09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f92146def348cbb0e69d82af358544": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1347ab833edf461ab333efd247e65f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d200755d6fa48f6b6491235e01eb1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "28fa45df03fe427fb37cbd0c62b9b434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3af4108409164ad0a5fffae05b809f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e839b9ea4de54ae5b44f819188f12ad7",
              "IPY_MODEL_ea03e9ddf22e4dcca85d530160a3742a",
              "IPY_MODEL_744df0015d3543679897f4310728b123"
            ],
            "layout": "IPY_MODEL_08f92146def348cbb0e69d82af358544"
          }
        },
        "3e1bfcebf9a64a0fb6859b1f7265ed07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe1e722806b419898e966f4e99dd2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4882b9e945904c8f8e2c86d1cf3b4324": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb74bbc86d841c1a21f301441dcec06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4882b9e945904c8f8e2c86d1cf3b4324",
            "placeholder": "​",
            "style": "IPY_MODEL_946a340620484b5dbf5052a77da93923",
            "value": " 2.73k/? [00:00&lt;00:00, 88.1kB/s]"
          }
        },
        "62445e6e258e451b9f229794b07976df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7024a207045e4a53ab651bd169ddd842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff5e164c162440e82c15a7c5dea8188",
            "placeholder": "​",
            "style": "IPY_MODEL_e33fd3cde50a4f579c2314282e3d76d7",
            "value": "openwebtext.py: "
          }
        },
        "744df0015d3543679897f4310728b123": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1347ab833edf461ab333efd247e65f1a",
            "placeholder": "​",
            "style": "IPY_MODEL_3fe1e722806b419898e966f4e99dd2c8",
            "value": " 7.35k/? [00:00&lt;00:00, 222kB/s]"
          }
        },
        "7ff5e164c162440e82c15a7c5dea8188": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fc42b134f049ca98ef711cb8c6fcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "946a340620484b5dbf5052a77da93923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8cc479375f7498a810287622998c015": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c2d4763783b442baa2254ba1fcc1f95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cc479375f7498a810287622998c015",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28fa45df03fe427fb37cbd0c62b9b434",
            "value": 1
          }
        },
        "e33fd3cde50a4f579c2314282e3d76d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e839b9ea4de54ae5b44f819188f12ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_061c2cf4e2ec41e6a558086c21ef7d09",
            "placeholder": "​",
            "style": "IPY_MODEL_62445e6e258e451b9f229794b07976df",
            "value": "README.md: "
          }
        },
        "ea03e9ddf22e4dcca85d530160a3742a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d200755d6fa48f6b6491235e01eb1b0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83fc42b134f049ca98ef711cb8c6fcbf",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
